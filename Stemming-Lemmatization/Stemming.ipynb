{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stemming.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmpmRHeaETdX"
      },
      "source": [
        "import pandas as pd \n",
        "from nltk.tokenize import word_tokenize \n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "import warnings \n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ck7S68zEoe9"
      },
      "source": [
        "text = \"\"\"\n",
        "\"Looking back on a childhood filled with events and memories, I find it rather difficult to pick one that leaves me with the fabled \"warm and fuzzy feelings.\" As the daughter of an Air Force major, I had the pleasure of traveling across America in many moving trips. I have visited the monstrous trees of the Sequoia National Forest, stood on the edge of the Grand Canyon and have jumped on the beds at Caesar's Palace in Lake Tahoe.\"\n",
        "\n",
        "\"The day I picked my dog up from the pound was one of the happiest days of both of our lives. I had gone to the pound just a week earlier with the idea that I would just \"look\" at a puppy. Of course, you can no more just look at those squiggling little faces so filled with hope and joy than you can stop the sun from setting in the evening. I knew within minutes of walking in the door that I would get a puppy… but it wasn't until I saw him that I knew I had found my puppy.\"\n",
        "\n",
        "\"Looking for houses was supposed to be a fun and exciting process. Unfortunately, none of the ones that we saw seemed to match the specifications that we had established. They were too small, too impersonal, too close to the neighbors. After days of finding nothing even close, we began to wonder: was there really a perfect house out there for us?\"\n",
        "\"\"\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "612BmuiDGCnh",
        "outputId": "c487ff75-2455-42e1-a4a1-4a956f820f80"
      },
      "source": [
        "text"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n\"Looking back on a childhood filled with events and memories, I find it rather difficult to pick one that leaves me with the fabled \"warm and fuzzy feelings.\" As the daughter of an Air Force major, I had the pleasure of traveling across America in many moving trips. I have visited the monstrous trees of the Sequoia National Forest, stood on the edge of the Grand Canyon and have jumped on the beds at Caesar\\'s Palace in Lake Tahoe.\"\\n\\n\"The day I picked my dog up from the pound was one of the happiest days of both of our lives. I had gone to the pound just a week earlier with the idea that I would just \"look\" at a puppy. Of course, you can no more just look at those squiggling little faces so filled with hope and joy than you can stop the sun from setting in the evening. I knew within minutes of walking in the door that I would get a puppy… but it wasn\\'t until I saw him that I knew I had found my puppy.\"\\n\\n\"Looking for houses was supposed to be a fun and exciting process. Unfortunately, none of the ones that we saw seemed to match the specifications that we had established. They were too small, too impersonal, too close to the neighbors. After days of finding nothing even close, we began to wonder: was there really a perfect house out there for us?\"\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AmekbVxGUPE"
      },
      "source": [
        "## let's create word tokens \n",
        "Tokenization breaks the raw text into words, sentences called tokens. These tokens help in understanding the context or developing the model for the NLP. The tokenization helps in interpreting the meaning of the text by analyzing the sequence of the words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yj0CI_CEGkkS",
        "outputId": "8f0bfff7-ade7-49b8-90c3-6be1e3161ca3"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XM7JHE3lGD-T",
        "outputId": "21f44f64-afe5-461d-c3d0-7fbcaaaaff03"
      },
      "source": [
        "# let's create word tokens \n",
        "tokens = word_tokenize(text.lower())\n",
        "\n",
        "print(tokens)\n",
        "print(len(tokens))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"''\", 'looking', 'back', 'on', 'a', 'childhood', 'filled', 'with', 'events', 'and', 'memories', ',', 'i', 'find', 'it', 'rather', 'difficult', 'to', 'pick', 'one', 'that', 'leaves', 'me', 'with', 'the', 'fabled', '``', 'warm', 'and', 'fuzzy', 'feelings', '.', \"''\", 'as', 'the', 'daughter', 'of', 'an', 'air', 'force', 'major', ',', 'i', 'had', 'the', 'pleasure', 'of', 'traveling', 'across', 'america', 'in', 'many', 'moving', 'trips', '.', 'i', 'have', 'visited', 'the', 'monstrous', 'trees', 'of', 'the', 'sequoia', 'national', 'forest', ',', 'stood', 'on', 'the', 'edge', 'of', 'the', 'grand', 'canyon', 'and', 'have', 'jumped', 'on', 'the', 'beds', 'at', 'caesar', \"'s\", 'palace', 'in', 'lake', 'tahoe', '.', \"''\", '``', 'the', 'day', 'i', 'picked', 'my', 'dog', 'up', 'from', 'the', 'pound', 'was', 'one', 'of', 'the', 'happiest', 'days', 'of', 'both', 'of', 'our', 'lives', '.', 'i', 'had', 'gone', 'to', 'the', 'pound', 'just', 'a', 'week', 'earlier', 'with', 'the', 'idea', 'that', 'i', 'would', 'just', '``', 'look', \"''\", 'at', 'a', 'puppy', '.', 'of', 'course', ',', 'you', 'can', 'no', 'more', 'just', 'look', 'at', 'those', 'squiggling', 'little', 'faces', 'so', 'filled', 'with', 'hope', 'and', 'joy', 'than', 'you', 'can', 'stop', 'the', 'sun', 'from', 'setting', 'in', 'the', 'evening', '.', 'i', 'knew', 'within', 'minutes', 'of', 'walking', 'in', 'the', 'door', 'that', 'i', 'would', 'get', 'a', 'puppy…', 'but', 'it', 'was', \"n't\", 'until', 'i', 'saw', 'him', 'that', 'i', 'knew', 'i', 'had', 'found', 'my', 'puppy', '.', \"''\", '``', 'looking', 'for', 'houses', 'was', 'supposed', 'to', 'be', 'a', 'fun', 'and', 'exciting', 'process', '.', 'unfortunately', ',', 'none', 'of', 'the', 'ones', 'that', 'we', 'saw', 'seemed', 'to', 'match', 'the', 'specifications', 'that', 'we', 'had', 'established', '.', 'they', 'were', 'too', 'small', ',', 'too', 'impersonal', ',', 'too', 'close', 'to', 'the', 'neighbors', '.', 'after', 'days', 'of', 'finding', 'nothing', 'even', 'close', ',', 'we', 'began', 'to', 'wonder', ':', 'was', 'there', 'really', 'a', 'perfect', 'house', 'out', 'there', 'for', 'us', '?', \"''\"]\n",
            "274\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAzoVjwuHHcR"
      },
      "source": [
        "[NLTK:Stemmer](https://www.nltk.org/howto/stem.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrL7cJP2Ge3p",
        "outputId": "d28de6fc-a063-4067-de6d-84824be6f007"
      },
      "source": [
        "stemmer = PorterStemmer()\n",
        "porter_stemmer = [stemmer.stem(token) for token in tokens]\n",
        "print(porter_stemmer)\n",
        "print(len(porter_stemmer))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"''\", 'look', 'back', 'on', 'a', 'childhood', 'fill', 'with', 'event', 'and', 'memori', ',', 'i', 'find', 'it', 'rather', 'difficult', 'to', 'pick', 'one', 'that', 'leav', 'me', 'with', 'the', 'fabl', '``', 'warm', 'and', 'fuzzi', 'feel', '.', \"''\", 'as', 'the', 'daughter', 'of', 'an', 'air', 'forc', 'major', ',', 'i', 'had', 'the', 'pleasur', 'of', 'travel', 'across', 'america', 'in', 'mani', 'move', 'trip', '.', 'i', 'have', 'visit', 'the', 'monstrou', 'tree', 'of', 'the', 'sequoia', 'nation', 'forest', ',', 'stood', 'on', 'the', 'edg', 'of', 'the', 'grand', 'canyon', 'and', 'have', 'jump', 'on', 'the', 'bed', 'at', 'caesar', \"'s\", 'palac', 'in', 'lake', 'taho', '.', \"''\", '``', 'the', 'day', 'i', 'pick', 'my', 'dog', 'up', 'from', 'the', 'pound', 'wa', 'one', 'of', 'the', 'happiest', 'day', 'of', 'both', 'of', 'our', 'live', '.', 'i', 'had', 'gone', 'to', 'the', 'pound', 'just', 'a', 'week', 'earlier', 'with', 'the', 'idea', 'that', 'i', 'would', 'just', '``', 'look', \"''\", 'at', 'a', 'puppi', '.', 'of', 'cours', ',', 'you', 'can', 'no', 'more', 'just', 'look', 'at', 'those', 'squiggl', 'littl', 'face', 'so', 'fill', 'with', 'hope', 'and', 'joy', 'than', 'you', 'can', 'stop', 'the', 'sun', 'from', 'set', 'in', 'the', 'even', '.', 'i', 'knew', 'within', 'minut', 'of', 'walk', 'in', 'the', 'door', 'that', 'i', 'would', 'get', 'a', 'puppy…', 'but', 'it', 'wa', \"n't\", 'until', 'i', 'saw', 'him', 'that', 'i', 'knew', 'i', 'had', 'found', 'my', 'puppi', '.', \"''\", '``', 'look', 'for', 'hous', 'wa', 'suppos', 'to', 'be', 'a', 'fun', 'and', 'excit', 'process', '.', 'unfortun', ',', 'none', 'of', 'the', 'one', 'that', 'we', 'saw', 'seem', 'to', 'match', 'the', 'specif', 'that', 'we', 'had', 'establish', '.', 'they', 'were', 'too', 'small', ',', 'too', 'imperson', ',', 'too', 'close', 'to', 'the', 'neighbor', '.', 'after', 'day', 'of', 'find', 'noth', 'even', 'close', ',', 'we', 'began', 'to', 'wonder', ':', 'wa', 'there', 'realli', 'a', 'perfect', 'hous', 'out', 'there', 'for', 'us', '?', \"''\"]\n",
            "274\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWMEWIFJHjic",
        "outputId": "6fe26e74-9f58-445b-d7c3-c449794b6700"
      },
      "source": [
        "stemmer = SnowballStemmer('english')\n",
        "snowball = [stemmer.stem(token) for token in tokens]\n",
        "print(snowball)\n",
        "print(len(snowball))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"''\", 'look', 'back', 'on', 'a', 'childhood', 'fill', 'with', 'event', 'and', 'memori', ',', 'i', 'find', 'it', 'rather', 'difficult', 'to', 'pick', 'one', 'that', 'leav', 'me', 'with', 'the', 'fabl', '``', 'warm', 'and', 'fuzzi', 'feel', '.', \"''\", 'as', 'the', 'daughter', 'of', 'an', 'air', 'forc', 'major', ',', 'i', 'had', 'the', 'pleasur', 'of', 'travel', 'across', 'america', 'in', 'mani', 'move', 'trip', '.', 'i', 'have', 'visit', 'the', 'monstrous', 'tree', 'of', 'the', 'sequoia', 'nation', 'forest', ',', 'stood', 'on', 'the', 'edg', 'of', 'the', 'grand', 'canyon', 'and', 'have', 'jump', 'on', 'the', 'bed', 'at', 'caesar', \"'s\", 'palac', 'in', 'lake', 'taho', '.', \"''\", '``', 'the', 'day', 'i', 'pick', 'my', 'dog', 'up', 'from', 'the', 'pound', 'was', 'one', 'of', 'the', 'happiest', 'day', 'of', 'both', 'of', 'our', 'live', '.', 'i', 'had', 'gone', 'to', 'the', 'pound', 'just', 'a', 'week', 'earlier', 'with', 'the', 'idea', 'that', 'i', 'would', 'just', '``', 'look', \"''\", 'at', 'a', 'puppi', '.', 'of', 'cours', ',', 'you', 'can', 'no', 'more', 'just', 'look', 'at', 'those', 'squiggl', 'littl', 'face', 'so', 'fill', 'with', 'hope', 'and', 'joy', 'than', 'you', 'can', 'stop', 'the', 'sun', 'from', 'set', 'in', 'the', 'even', '.', 'i', 'knew', 'within', 'minut', 'of', 'walk', 'in', 'the', 'door', 'that', 'i', 'would', 'get', 'a', 'puppy…', 'but', 'it', 'was', \"n't\", 'until', 'i', 'saw', 'him', 'that', 'i', 'knew', 'i', 'had', 'found', 'my', 'puppi', '.', \"''\", '``', 'look', 'for', 'hous', 'was', 'suppos', 'to', 'be', 'a', 'fun', 'and', 'excit', 'process', '.', 'unfortun', ',', 'none', 'of', 'the', 'one', 'that', 'we', 'saw', 'seem', 'to', 'match', 'the', 'specif', 'that', 'we', 'had', 'establish', '.', 'they', 'were', 'too', 'small', ',', 'too', 'imperson', ',', 'too', 'close', 'to', 'the', 'neighbor', '.', 'after', 'day', 'of', 'find', 'noth', 'even', 'close', ',', 'we', 'began', 'to', 'wonder', ':', 'was', 'there', 'realli', 'a', 'perfect', 'hous', 'out', 'there', 'for', 'us', '?', \"''\"]\n",
            "274\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "d_rLccKFH0ob",
        "outputId": "9bce6b44-b69b-4fa8-a409-97a923999096"
      },
      "source": [
        "df = pd.DataFrame({'token':tokens, 'Porter_STEMMER':porter_stemmer, 'SNOWBALL_STEMMER':snowball})\n",
        "df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token</th>\n",
              "      <th>Porter_STEMMER</th>\n",
              "      <th>SNOWBALL_STEMMER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>''</td>\n",
              "      <td>''</td>\n",
              "      <td>''</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>looking</td>\n",
              "      <td>look</td>\n",
              "      <td>look</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>back</td>\n",
              "      <td>back</td>\n",
              "      <td>back</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>on</td>\n",
              "      <td>on</td>\n",
              "      <td>on</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     token Porter_STEMMER SNOWBALL_STEMMER\n",
              "0       ''             ''               ''\n",
              "1  looking           look             look\n",
              "2     back           back             back\n",
              "3       on             on               on\n",
              "4        a              a                a"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ub9NsK6QIJMc",
        "outputId": "30d1b4e0-0e11-4cf6-d9e0-e503cb41c186"
      },
      "source": [
        "# let's check the changed tokens only \n",
        "df[(df.token != df.Porter_STEMMER) | (df.token != df.SNOWBALL_STEMMER)]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token</th>\n",
              "      <th>Porter_STEMMER</th>\n",
              "      <th>SNOWBALL_STEMMER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>looking</td>\n",
              "      <td>look</td>\n",
              "      <td>look</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>filled</td>\n",
              "      <td>fill</td>\n",
              "      <td>fill</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>events</td>\n",
              "      <td>event</td>\n",
              "      <td>event</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>memories</td>\n",
              "      <td>memori</td>\n",
              "      <td>memori</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>leaves</td>\n",
              "      <td>leav</td>\n",
              "      <td>leav</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>fabled</td>\n",
              "      <td>fabl</td>\n",
              "      <td>fabl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>fuzzy</td>\n",
              "      <td>fuzzi</td>\n",
              "      <td>fuzzi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>feelings</td>\n",
              "      <td>feel</td>\n",
              "      <td>feel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>force</td>\n",
              "      <td>forc</td>\n",
              "      <td>forc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>pleasure</td>\n",
              "      <td>pleasur</td>\n",
              "      <td>pleasur</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>traveling</td>\n",
              "      <td>travel</td>\n",
              "      <td>travel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>many</td>\n",
              "      <td>mani</td>\n",
              "      <td>mani</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>moving</td>\n",
              "      <td>move</td>\n",
              "      <td>move</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>trips</td>\n",
              "      <td>trip</td>\n",
              "      <td>trip</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>visited</td>\n",
              "      <td>visit</td>\n",
              "      <td>visit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>monstrous</td>\n",
              "      <td>monstrou</td>\n",
              "      <td>monstrous</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>trees</td>\n",
              "      <td>tree</td>\n",
              "      <td>tree</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>national</td>\n",
              "      <td>nation</td>\n",
              "      <td>nation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>edge</td>\n",
              "      <td>edg</td>\n",
              "      <td>edg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>jumped</td>\n",
              "      <td>jump</td>\n",
              "      <td>jump</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>beds</td>\n",
              "      <td>bed</td>\n",
              "      <td>bed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>palace</td>\n",
              "      <td>palac</td>\n",
              "      <td>palac</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>tahoe</td>\n",
              "      <td>taho</td>\n",
              "      <td>taho</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>picked</td>\n",
              "      <td>pick</td>\n",
              "      <td>pick</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>was</td>\n",
              "      <td>wa</td>\n",
              "      <td>was</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>days</td>\n",
              "      <td>day</td>\n",
              "      <td>day</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>lives</td>\n",
              "      <td>live</td>\n",
              "      <td>live</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135</th>\n",
              "      <td>puppy</td>\n",
              "      <td>puppi</td>\n",
              "      <td>puppi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138</th>\n",
              "      <td>course</td>\n",
              "      <td>cours</td>\n",
              "      <td>cours</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>squiggling</td>\n",
              "      <td>squiggl</td>\n",
              "      <td>squiggl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>little</td>\n",
              "      <td>littl</td>\n",
              "      <td>littl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>faces</td>\n",
              "      <td>face</td>\n",
              "      <td>face</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152</th>\n",
              "      <td>filled</td>\n",
              "      <td>fill</td>\n",
              "      <td>fill</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>setting</td>\n",
              "      <td>set</td>\n",
              "      <td>set</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>evening</td>\n",
              "      <td>even</td>\n",
              "      <td>even</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>minutes</td>\n",
              "      <td>minut</td>\n",
              "      <td>minut</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>walking</td>\n",
              "      <td>walk</td>\n",
              "      <td>walk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>186</th>\n",
              "      <td>was</td>\n",
              "      <td>wa</td>\n",
              "      <td>was</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>puppy</td>\n",
              "      <td>puppi</td>\n",
              "      <td>puppi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>looking</td>\n",
              "      <td>look</td>\n",
              "      <td>look</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205</th>\n",
              "      <td>houses</td>\n",
              "      <td>hous</td>\n",
              "      <td>hous</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206</th>\n",
              "      <td>was</td>\n",
              "      <td>wa</td>\n",
              "      <td>was</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207</th>\n",
              "      <td>supposed</td>\n",
              "      <td>suppos</td>\n",
              "      <td>suppos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>213</th>\n",
              "      <td>exciting</td>\n",
              "      <td>excit</td>\n",
              "      <td>excit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>216</th>\n",
              "      <td>unfortunately</td>\n",
              "      <td>unfortun</td>\n",
              "      <td>unfortun</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221</th>\n",
              "      <td>ones</td>\n",
              "      <td>one</td>\n",
              "      <td>one</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>225</th>\n",
              "      <td>seemed</td>\n",
              "      <td>seem</td>\n",
              "      <td>seem</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229</th>\n",
              "      <td>specifications</td>\n",
              "      <td>specif</td>\n",
              "      <td>specif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>233</th>\n",
              "      <td>established</td>\n",
              "      <td>establish</td>\n",
              "      <td>establish</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>241</th>\n",
              "      <td>impersonal</td>\n",
              "      <td>imperson</td>\n",
              "      <td>imperson</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>247</th>\n",
              "      <td>neighbors</td>\n",
              "      <td>neighbor</td>\n",
              "      <td>neighbor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>250</th>\n",
              "      <td>days</td>\n",
              "      <td>day</td>\n",
              "      <td>day</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>252</th>\n",
              "      <td>finding</td>\n",
              "      <td>find</td>\n",
              "      <td>find</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253</th>\n",
              "      <td>nothing</td>\n",
              "      <td>noth</td>\n",
              "      <td>noth</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262</th>\n",
              "      <td>was</td>\n",
              "      <td>wa</td>\n",
              "      <td>was</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>264</th>\n",
              "      <td>really</td>\n",
              "      <td>realli</td>\n",
              "      <td>realli</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>267</th>\n",
              "      <td>house</td>\n",
              "      <td>hous</td>\n",
              "      <td>hous</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              token Porter_STEMMER SNOWBALL_STEMMER\n",
              "1           looking           look             look\n",
              "6            filled           fill             fill\n",
              "8            events          event            event\n",
              "10         memories         memori           memori\n",
              "21           leaves           leav             leav\n",
              "25           fabled           fabl             fabl\n",
              "29            fuzzy          fuzzi            fuzzi\n",
              "30         feelings           feel             feel\n",
              "39            force           forc             forc\n",
              "45         pleasure        pleasur          pleasur\n",
              "47        traveling         travel           travel\n",
              "51             many           mani             mani\n",
              "52           moving           move             move\n",
              "53            trips           trip             trip\n",
              "57          visited          visit            visit\n",
              "59        monstrous       monstrou        monstrous\n",
              "60            trees           tree             tree\n",
              "64         national         nation           nation\n",
              "70             edge            edg              edg\n",
              "77           jumped           jump             jump\n",
              "80             beds            bed              bed\n",
              "84           palace          palac            palac\n",
              "87            tahoe           taho             taho\n",
              "94           picked           pick             pick\n",
              "101             was             wa              was\n",
              "106            days            day              day\n",
              "111           lives           live             live\n",
              "135           puppy          puppi            puppi\n",
              "138          course          cours            cours\n",
              "148      squiggling        squiggl          squiggl\n",
              "149          little          littl            littl\n",
              "150           faces           face             face\n",
              "152          filled           fill             fill\n",
              "164         setting            set              set\n",
              "167         evening           even             even\n",
              "172         minutes          minut            minut\n",
              "174         walking           walk             walk\n",
              "186             was             wa              was\n",
              "199           puppy          puppi            puppi\n",
              "203         looking           look             look\n",
              "205          houses           hous             hous\n",
              "206             was             wa              was\n",
              "207        supposed         suppos           suppos\n",
              "213        exciting          excit            excit\n",
              "216   unfortunately       unfortun         unfortun\n",
              "221            ones            one              one\n",
              "225          seemed           seem             seem\n",
              "229  specifications         specif           specif\n",
              "233     established      establish        establish\n",
              "241      impersonal       imperson         imperson\n",
              "247       neighbors       neighbor         neighbor\n",
              "250            days            day              day\n",
              "252         finding           find             find\n",
              "253         nothing           noth             noth\n",
              "262             was             wa              was\n",
              "264          really         realli           realli\n",
              "267           house           hous             hous"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "OcihNx8yIexw",
        "outputId": "fa1f5492-c924-47a9-c0eb-2bbaa39d7c9f"
      },
      "source": [
        "# unchanged values \n",
        "df[(df.token == df.Porter_STEMMER) | (df.token == df.SNOWBALL_STEMMER)]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token</th>\n",
              "      <th>Porter_STEMMER</th>\n",
              "      <th>SNOWBALL_STEMMER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>''</td>\n",
              "      <td>''</td>\n",
              "      <td>''</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>back</td>\n",
              "      <td>back</td>\n",
              "      <td>back</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>on</td>\n",
              "      <td>on</td>\n",
              "      <td>on</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>childhood</td>\n",
              "      <td>childhood</td>\n",
              "      <td>childhood</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>269</th>\n",
              "      <td>there</td>\n",
              "      <td>there</td>\n",
              "      <td>there</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270</th>\n",
              "      <td>for</td>\n",
              "      <td>for</td>\n",
              "      <td>for</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>271</th>\n",
              "      <td>us</td>\n",
              "      <td>us</td>\n",
              "      <td>us</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>272</th>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>273</th>\n",
              "      <td>''</td>\n",
              "      <td>''</td>\n",
              "      <td>''</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>222 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         token Porter_STEMMER SNOWBALL_STEMMER\n",
              "0           ''             ''               ''\n",
              "2         back           back             back\n",
              "3           on             on               on\n",
              "4            a              a                a\n",
              "5    childhood      childhood        childhood\n",
              "..         ...            ...              ...\n",
              "269      there          there            there\n",
              "270        for            for              for\n",
              "271         us             us               us\n",
              "272          ?              ?                ?\n",
              "273         ''             ''               ''\n",
              "\n",
              "[222 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAeC5IUkIlqe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}