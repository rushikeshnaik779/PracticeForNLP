{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lemma.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAsvGaa3Kcus"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCuURQuZEQgq"
      },
      "source": [
        "[WORDNET_LEMMATIZATION](https://www.nltk.org/_modules/nltk/stem/wordnet.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVnoxxjWEDCZ"
      },
      "source": [
        "text = \"\"\"\"Looking back on a childhood filled with events and memories, I find it rather difficult to pick one that leaves me with the fabled \"warm and fuzzy feelings.\" As the daughter of an Air Force major, I had the pleasure of traveling across America in many moving trips. I have visited the monstrous trees of the Sequoia National Forest, stood on the edge of the Grand Canyon and have jumped on the beds at Caesar's Palace in Lake Tahoe.\"\n",
        "\n",
        "\"The day I picked my dog up from the pound was one of the happiest days of both of our lives. I had gone to the pound just a week earlier with the idea that I would just \"look\" at a puppy. Of course, you can no more just look at those squiggling little faces so filled with hope and joy than you can stop the sun from setting in the evening. I knew within minutes of walking in the door that I would get a puppy… but it wasn't until I saw him that I knew I had found my puppy.\"\n",
        "\n",
        "\"Looking for houses was supposed to be a fun and exciting process. Unfortunately, none of the ones that we saw seemed to match the specifications that we had established. They were too small, too impersonal, too close to the neighbors. After days of finding nothing even close, we began to wonder: was there really a perfect house out there for us?\"\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CEHZox9Ejmv",
        "outputId": "7ca75dc6-e59d-46a2-a1ad-95717be85492"
      },
      "source": [
        "print(text)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\"Looking back on a childhood filled with events and memories, I find it rather difficult to pick one that leaves me with the fabled \"warm and fuzzy feelings.\" As the daughter of an Air Force major, I had the pleasure of traveling across America in many moving trips. I have visited the monstrous trees of the Sequoia National Forest, stood on the edge of the Grand Canyon and have jumped on the beds at Caesar's Palace in Lake Tahoe.\"\n",
            "\n",
            "\"The day I picked my dog up from the pound was one of the happiest days of both of our lives. I had gone to the pound just a week earlier with the idea that I would just \"look\" at a puppy. Of course, you can no more just look at those squiggling little faces so filled with hope and joy than you can stop the sun from setting in the evening. I knew within minutes of walking in the door that I would get a puppy… but it wasn't until I saw him that I knew I had found my puppy.\"\n",
            "\n",
            "\"Looking for houses was supposed to be a fun and exciting process. Unfortunately, none of the ones that we saw seemed to match the specifications that we had established. They were too small, too impersonal, too close to the neighbors. After days of finding nothing even close, we began to wonder: was there really a perfect house out there for us?\"\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xKNlMt1Exob",
        "outputId": "78392d4d-9b60-45de-a583-327c40078c34"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsEpS8ezEkzR",
        "outputId": "0eb2b850-980a-4a54-d697-43df5dbcaf23"
      },
      "source": [
        "tokens = word_tokenize(text)\n",
        "print('Printing Tokens\\n', tokens)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Printing Tokens\n",
            " ['``', 'Looking', 'back', 'on', 'a', 'childhood', 'filled', 'with', 'events', 'and', 'memories', ',', 'I', 'find', 'it', 'rather', 'difficult', 'to', 'pick', 'one', 'that', 'leaves', 'me', 'with', 'the', 'fabled', '``', 'warm', 'and', 'fuzzy', 'feelings', '.', \"''\", 'As', 'the', 'daughter', 'of', 'an', 'Air', 'Force', 'major', ',', 'I', 'had', 'the', 'pleasure', 'of', 'traveling', 'across', 'America', 'in', 'many', 'moving', 'trips', '.', 'I', 'have', 'visited', 'the', 'monstrous', 'trees', 'of', 'the', 'Sequoia', 'National', 'Forest', ',', 'stood', 'on', 'the', 'edge', 'of', 'the', 'Grand', 'Canyon', 'and', 'have', 'jumped', 'on', 'the', 'beds', 'at', 'Caesar', \"'s\", 'Palace', 'in', 'Lake', 'Tahoe', '.', \"''\", '``', 'The', 'day', 'I', 'picked', 'my', 'dog', 'up', 'from', 'the', 'pound', 'was', 'one', 'of', 'the', 'happiest', 'days', 'of', 'both', 'of', 'our', 'lives', '.', 'I', 'had', 'gone', 'to', 'the', 'pound', 'just', 'a', 'week', 'earlier', 'with', 'the', 'idea', 'that', 'I', 'would', 'just', '``', 'look', \"''\", 'at', 'a', 'puppy', '.', 'Of', 'course', ',', 'you', 'can', 'no', 'more', 'just', 'look', 'at', 'those', 'squiggling', 'little', 'faces', 'so', 'filled', 'with', 'hope', 'and', 'joy', 'than', 'you', 'can', 'stop', 'the', 'sun', 'from', 'setting', 'in', 'the', 'evening', '.', 'I', 'knew', 'within', 'minutes', 'of', 'walking', 'in', 'the', 'door', 'that', 'I', 'would', 'get', 'a', 'puppy…', 'but', 'it', 'was', \"n't\", 'until', 'I', 'saw', 'him', 'that', 'I', 'knew', 'I', 'had', 'found', 'my', 'puppy', '.', \"''\", '``', 'Looking', 'for', 'houses', 'was', 'supposed', 'to', 'be', 'a', 'fun', 'and', 'exciting', 'process', '.', 'Unfortunately', ',', 'none', 'of', 'the', 'ones', 'that', 'we', 'saw', 'seemed', 'to', 'match', 'the', 'specifications', 'that', 'we', 'had', 'established', '.', 'They', 'were', 'too', 'small', ',', 'too', 'impersonal', ',', 'too', 'close', 'to', 'the', 'neighbors', '.', 'After', 'days', 'of', 'finding', 'nothing', 'even', 'close', ',', 'we', 'began', 'to', 'wonder', ':', 'was', 'there', 'really', 'a', 'perfect', 'house', 'out', 'there', 'for', 'us', '?', \"''\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sIuTZ9KFRpe",
        "outputId": "a72e5e48-d9b6-413c-f1e3-e594fec2a2ea"
      },
      "source": [
        "nltk.download('wordnet')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmqFAQ2UEvYe",
        "outputId": "9625238f-dfe2-4912-ebfe-edaf954e003a"
      },
      "source": [
        "word_lemmet = WordNetLemmatizer()\n",
        "lemmetized = [word_lemmet.lemmatize(token) for token in tokens]\n",
        "print(lemmetized)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['``', 'Looking', 'back', 'on', 'a', 'childhood', 'filled', 'with', 'event', 'and', 'memory', ',', 'I', 'find', 'it', 'rather', 'difficult', 'to', 'pick', 'one', 'that', 'leaf', 'me', 'with', 'the', 'fabled', '``', 'warm', 'and', 'fuzzy', 'feeling', '.', \"''\", 'As', 'the', 'daughter', 'of', 'an', 'Air', 'Force', 'major', ',', 'I', 'had', 'the', 'pleasure', 'of', 'traveling', 'across', 'America', 'in', 'many', 'moving', 'trip', '.', 'I', 'have', 'visited', 'the', 'monstrous', 'tree', 'of', 'the', 'Sequoia', 'National', 'Forest', ',', 'stood', 'on', 'the', 'edge', 'of', 'the', 'Grand', 'Canyon', 'and', 'have', 'jumped', 'on', 'the', 'bed', 'at', 'Caesar', \"'s\", 'Palace', 'in', 'Lake', 'Tahoe', '.', \"''\", '``', 'The', 'day', 'I', 'picked', 'my', 'dog', 'up', 'from', 'the', 'pound', 'wa', 'one', 'of', 'the', 'happiest', 'day', 'of', 'both', 'of', 'our', 'life', '.', 'I', 'had', 'gone', 'to', 'the', 'pound', 'just', 'a', 'week', 'earlier', 'with', 'the', 'idea', 'that', 'I', 'would', 'just', '``', 'look', \"''\", 'at', 'a', 'puppy', '.', 'Of', 'course', ',', 'you', 'can', 'no', 'more', 'just', 'look', 'at', 'those', 'squiggling', 'little', 'face', 'so', 'filled', 'with', 'hope', 'and', 'joy', 'than', 'you', 'can', 'stop', 'the', 'sun', 'from', 'setting', 'in', 'the', 'evening', '.', 'I', 'knew', 'within', 'minute', 'of', 'walking', 'in', 'the', 'door', 'that', 'I', 'would', 'get', 'a', 'puppy…', 'but', 'it', 'wa', \"n't\", 'until', 'I', 'saw', 'him', 'that', 'I', 'knew', 'I', 'had', 'found', 'my', 'puppy', '.', \"''\", '``', 'Looking', 'for', 'house', 'wa', 'supposed', 'to', 'be', 'a', 'fun', 'and', 'exciting', 'process', '.', 'Unfortunately', ',', 'none', 'of', 'the', 'one', 'that', 'we', 'saw', 'seemed', 'to', 'match', 'the', 'specification', 'that', 'we', 'had', 'established', '.', 'They', 'were', 'too', 'small', ',', 'too', 'impersonal', ',', 'too', 'close', 'to', 'the', 'neighbor', '.', 'After', 'day', 'of', 'finding', 'nothing', 'even', 'close', ',', 'we', 'began', 'to', 'wonder', ':', 'wa', 'there', 'really', 'a', 'perfect', 'house', 'out', 'there', 'for', 'u', '?', \"''\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkZ-eBVLFmbB"
      },
      "source": [
        "#### also let's compare lemmatization and stemming "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiEPZnY-FP7g",
        "outputId": "5f362286-3233-4e51-cc12-83c27c6b70e9"
      },
      "source": [
        "from nltk.stem.porter import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "stemmed = [stemmer.stem(token) for token in tokens]\n",
        "print(stemmed)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['``', 'look', 'back', 'on', 'a', 'childhood', 'fill', 'with', 'event', 'and', 'memori', ',', 'I', 'find', 'it', 'rather', 'difficult', 'to', 'pick', 'one', 'that', 'leav', 'me', 'with', 'the', 'fabl', '``', 'warm', 'and', 'fuzzi', 'feel', '.', \"''\", 'As', 'the', 'daughter', 'of', 'an', 'air', 'forc', 'major', ',', 'I', 'had', 'the', 'pleasur', 'of', 'travel', 'across', 'america', 'in', 'mani', 'move', 'trip', '.', 'I', 'have', 'visit', 'the', 'monstrou', 'tree', 'of', 'the', 'sequoia', 'nation', 'forest', ',', 'stood', 'on', 'the', 'edg', 'of', 'the', 'grand', 'canyon', 'and', 'have', 'jump', 'on', 'the', 'bed', 'at', 'caesar', \"'s\", 'palac', 'in', 'lake', 'taho', '.', \"''\", '``', 'the', 'day', 'I', 'pick', 'my', 'dog', 'up', 'from', 'the', 'pound', 'wa', 'one', 'of', 'the', 'happiest', 'day', 'of', 'both', 'of', 'our', 'live', '.', 'I', 'had', 'gone', 'to', 'the', 'pound', 'just', 'a', 'week', 'earlier', 'with', 'the', 'idea', 'that', 'I', 'would', 'just', '``', 'look', \"''\", 'at', 'a', 'puppi', '.', 'Of', 'cours', ',', 'you', 'can', 'no', 'more', 'just', 'look', 'at', 'those', 'squiggl', 'littl', 'face', 'so', 'fill', 'with', 'hope', 'and', 'joy', 'than', 'you', 'can', 'stop', 'the', 'sun', 'from', 'set', 'in', 'the', 'even', '.', 'I', 'knew', 'within', 'minut', 'of', 'walk', 'in', 'the', 'door', 'that', 'I', 'would', 'get', 'a', 'puppy…', 'but', 'it', 'wa', \"n't\", 'until', 'I', 'saw', 'him', 'that', 'I', 'knew', 'I', 'had', 'found', 'my', 'puppi', '.', \"''\", '``', 'look', 'for', 'hous', 'wa', 'suppos', 'to', 'be', 'a', 'fun', 'and', 'excit', 'process', '.', 'unfortun', ',', 'none', 'of', 'the', 'one', 'that', 'we', 'saw', 'seem', 'to', 'match', 'the', 'specif', 'that', 'we', 'had', 'establish', '.', 'they', 'were', 'too', 'small', ',', 'too', 'imperson', ',', 'too', 'close', 'to', 'the', 'neighbor', '.', 'after', 'day', 'of', 'find', 'noth', 'even', 'close', ',', 'we', 'began', 'to', 'wonder', ':', 'wa', 'there', 'realli', 'a', 'perfect', 'hous', 'out', 'there', 'for', 'us', '?', \"''\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "TPnSImMoF0SM",
        "outputId": "4a1c7378-3bb2-4ead-ee16-55ddedea5dd6"
      },
      "source": [
        "import pandas as pd \n",
        "df = pd.DataFrame(data={'token': tokens, 'stemmed': stemmed, 'lemmitized': lemmetized})\n",
        "df.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token</th>\n",
              "      <th>stemmed</th>\n",
              "      <th>lemmitized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>``</td>\n",
              "      <td>``</td>\n",
              "      <td>``</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Looking</td>\n",
              "      <td>look</td>\n",
              "      <td>Looking</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>back</td>\n",
              "      <td>back</td>\n",
              "      <td>back</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>on</td>\n",
              "      <td>on</td>\n",
              "      <td>on</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     token stemmed lemmitized\n",
              "0       ``      ``         ``\n",
              "1  Looking    look    Looking\n",
              "2     back    back       back\n",
              "3       on      on         on\n",
              "4        a       a          a"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "1FUKuhWyGDpg",
        "outputId": "4ddfca8b-6125-4b36-9b31-c63c1c13067f"
      },
      "source": [
        "# different than tokens \n",
        "df[(df.token != df.stemmed) | (df.token != df.lemmitized)]\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token</th>\n",
              "      <th>stemmed</th>\n",
              "      <th>lemmitized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Looking</td>\n",
              "      <td>look</td>\n",
              "      <td>Looking</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>filled</td>\n",
              "      <td>fill</td>\n",
              "      <td>filled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>events</td>\n",
              "      <td>event</td>\n",
              "      <td>event</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>memories</td>\n",
              "      <td>memori</td>\n",
              "      <td>memory</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>leaves</td>\n",
              "      <td>leav</td>\n",
              "      <td>leaf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253</th>\n",
              "      <td>nothing</td>\n",
              "      <td>noth</td>\n",
              "      <td>nothing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262</th>\n",
              "      <td>was</td>\n",
              "      <td>wa</td>\n",
              "      <td>wa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>264</th>\n",
              "      <td>really</td>\n",
              "      <td>realli</td>\n",
              "      <td>really</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>267</th>\n",
              "      <td>house</td>\n",
              "      <td>hous</td>\n",
              "      <td>house</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>271</th>\n",
              "      <td>us</td>\n",
              "      <td>us</td>\n",
              "      <td>u</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>69 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        token stemmed lemmitized\n",
              "1     Looking    look    Looking\n",
              "6      filled    fill     filled\n",
              "8      events   event      event\n",
              "10   memories  memori     memory\n",
              "21     leaves    leav       leaf\n",
              "..        ...     ...        ...\n",
              "253   nothing    noth    nothing\n",
              "262       was      wa         wa\n",
              "264    really  realli     really\n",
              "267     house    hous      house\n",
              "271        us      us          u\n",
              "\n",
              "[69 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        },
        "id": "SaLi541sGO3Y",
        "outputId": "3cd38b40-e842-44a2-fd79-db2f41bc8c0e"
      },
      "source": [
        "df[(df.token != df.lemmitized)]\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token</th>\n",
              "      <th>stemmed</th>\n",
              "      <th>lemmitized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>events</td>\n",
              "      <td>event</td>\n",
              "      <td>event</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>memories</td>\n",
              "      <td>memori</td>\n",
              "      <td>memory</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>leaves</td>\n",
              "      <td>leav</td>\n",
              "      <td>leaf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>feelings</td>\n",
              "      <td>feel</td>\n",
              "      <td>feeling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>trips</td>\n",
              "      <td>trip</td>\n",
              "      <td>trip</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>trees</td>\n",
              "      <td>tree</td>\n",
              "      <td>tree</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>beds</td>\n",
              "      <td>bed</td>\n",
              "      <td>bed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>was</td>\n",
              "      <td>wa</td>\n",
              "      <td>wa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>days</td>\n",
              "      <td>day</td>\n",
              "      <td>day</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>lives</td>\n",
              "      <td>live</td>\n",
              "      <td>life</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>faces</td>\n",
              "      <td>face</td>\n",
              "      <td>face</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>minutes</td>\n",
              "      <td>minut</td>\n",
              "      <td>minute</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>186</th>\n",
              "      <td>was</td>\n",
              "      <td>wa</td>\n",
              "      <td>wa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205</th>\n",
              "      <td>houses</td>\n",
              "      <td>hous</td>\n",
              "      <td>house</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206</th>\n",
              "      <td>was</td>\n",
              "      <td>wa</td>\n",
              "      <td>wa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221</th>\n",
              "      <td>ones</td>\n",
              "      <td>one</td>\n",
              "      <td>one</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229</th>\n",
              "      <td>specifications</td>\n",
              "      <td>specif</td>\n",
              "      <td>specification</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>247</th>\n",
              "      <td>neighbors</td>\n",
              "      <td>neighbor</td>\n",
              "      <td>neighbor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>250</th>\n",
              "      <td>days</td>\n",
              "      <td>day</td>\n",
              "      <td>day</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262</th>\n",
              "      <td>was</td>\n",
              "      <td>wa</td>\n",
              "      <td>wa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>271</th>\n",
              "      <td>us</td>\n",
              "      <td>us</td>\n",
              "      <td>u</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              token   stemmed     lemmitized\n",
              "8            events     event          event\n",
              "10         memories    memori         memory\n",
              "21           leaves      leav           leaf\n",
              "30         feelings      feel        feeling\n",
              "53            trips      trip           trip\n",
              "60            trees      tree           tree\n",
              "80             beds       bed            bed\n",
              "101             was        wa             wa\n",
              "106            days       day            day\n",
              "111           lives      live           life\n",
              "150           faces      face           face\n",
              "172         minutes     minut         minute\n",
              "186             was        wa             wa\n",
              "205          houses      hous          house\n",
              "206             was        wa             wa\n",
              "221            ones       one            one\n",
              "229  specifications    specif  specification\n",
              "247       neighbors  neighbor       neighbor\n",
              "250            days       day            day\n",
              "262             was        wa             wa\n",
              "271              us        us              u"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "ePNUJlTmGZTU",
        "outputId": "8ba81b95-5fe6-4664-e720-72333b22413a"
      },
      "source": [
        "df[(df.token == df.lemmitized)]\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token</th>\n",
              "      <th>stemmed</th>\n",
              "      <th>lemmitized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>``</td>\n",
              "      <td>``</td>\n",
              "      <td>``</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Looking</td>\n",
              "      <td>look</td>\n",
              "      <td>Looking</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>back</td>\n",
              "      <td>back</td>\n",
              "      <td>back</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>on</td>\n",
              "      <td>on</td>\n",
              "      <td>on</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>268</th>\n",
              "      <td>out</td>\n",
              "      <td>out</td>\n",
              "      <td>out</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>269</th>\n",
              "      <td>there</td>\n",
              "      <td>there</td>\n",
              "      <td>there</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270</th>\n",
              "      <td>for</td>\n",
              "      <td>for</td>\n",
              "      <td>for</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>272</th>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>273</th>\n",
              "      <td>''</td>\n",
              "      <td>''</td>\n",
              "      <td>''</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>253 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       token stemmed lemmitized\n",
              "0         ``      ``         ``\n",
              "1    Looking    look    Looking\n",
              "2       back    back       back\n",
              "3         on      on         on\n",
              "4          a       a          a\n",
              "..       ...     ...        ...\n",
              "268      out     out        out\n",
              "269    there   there      there\n",
              "270      for     for        for\n",
              "272        ?       ?          ?\n",
              "273       ''      ''         ''\n",
              "\n",
              "[253 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTkialaOGhzL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}