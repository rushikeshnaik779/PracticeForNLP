{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basic Language Model .ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "j679LTlfuk7A"
      },
      "source": [
        "from nltk.corpus import reuters "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxUIisXQvT0m"
      },
      "source": [
        "from nltk import bigrams, trigrams"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EWwFvx0vYHl"
      },
      "source": [
        "from collections import Counter, defaultdict"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVWJKafJvb7d",
        "outputId": "82a6315d-ec2d-477b-af63-81b8a859ae78"
      },
      "source": [
        "# creating a placeholder for model \n",
        "\n",
        "model = defaultdict(lambda: defaultdict(lambda: 0))\n",
        "print(model)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(<function <lambda> at 0x7ff4ee3131e0>, {})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFuNjv-Gv1yw",
        "outputId": "e028ecee-17d1-41b1-844e-1d29d67a1a28"
      },
      "source": [
        "import nltk \n",
        "nltk.download('reuters')\n",
        "nltk.download('punkt')\n",
        "# count frequency of co-occurance \n",
        "for sentence in reuters.sents():\n",
        "    for w1, w2, w3, in trigrams(sentence, pad_right=True, pad_left=True):\n",
        "        model[(w1, w2)][w3] += 1\n",
        "\n",
        "\n",
        "# let;s transform \n",
        "\n",
        "for w1_w2 in model:\n",
        "    total_count = float(sum(model[w1_w2].values()))\n",
        "\n",
        "    for w3 in model[w1_w2]:\n",
        "        model[w1_w2][w3] /= total_count"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]   Package reuters is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oathx2cxs2A",
        "outputId": "967548f5-a245-4582-d73a-c173994ab495"
      },
      "source": [
        "dict(model[\"the\", \"protest\"])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{',': 0.6666666666666666, 'action': 0.3333333333333333}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNgzLLzryPzY",
        "outputId": "5c8cc625-1bb5-4e7a-f772-3d10167cab26"
      },
      "source": [
        "dict(model[\"USA\", \"and\"])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Bennigan': 0.5, 'strong': 0.5}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6foovY216WFm"
      },
      "source": [
        "import random\n",
        "def gen(text):\n",
        "# starting words \n",
        "\n",
        "    sentence_finished = False\n",
        "    while not sentence_finished:\n",
        "        # select a random probability threshold \n",
        "\n",
        "        r = random.random()\n",
        "        accumulator = .0\n",
        "\n",
        "        for word in model[tuple(text[-2:])].keys():\n",
        "            accumulator += model[tuple(text[-2:])][word]\n",
        "\n",
        "            # select words that are above the probability threshold\n",
        "            if accumulator >= r:\n",
        "                text.append(word)\n",
        "                break\n",
        "\n",
        "        \n",
        "        if text[-2:] == [None, None]:\n",
        "            sentence_finished = True\n",
        "        \n",
        "    print(' '.join([t for t in text if t]))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgskTuqEBIOF",
        "outputId": "0fae7eb9-43ea-4fab-fa10-bef610568b6a"
      },
      "source": [
        "gen(['time', 'of'])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time of booming exports .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pP0ooreBKOZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}