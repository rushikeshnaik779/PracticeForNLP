{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ChatBot/Building My OwnChatBot",
      "provenance": [],
      "authorship_tag": "ABX9TyOC4h68RLq2bIlYRlEG9wRv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rushikeshnaik779/PracticeForNLP/blob/main/ChatBot%20V1/ChatBot_Building_My_OwnChatBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f8jMJ447rJd",
        "outputId": "e889dec3-707e-4acd-c5b1-6e5fe6605450"
      },
      "source": [
        "import numpy as np \n",
        "import gensim \n",
        "\n",
        "print(gensim.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACZoCT5h77T8"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "class TqdmUpto(tqdm):\n",
        "\n",
        "    def Update_to(self, b=1, bsize=1, tsize=None):\n",
        "        if tsize is not None : self.total = tsize\n",
        "        self.update(b * bsize - self.n)\n",
        "        "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldR1Mf9S8qSK",
        "outputId": "4d0fdd8b-9699-4dbf-9840-b5db91283b16"
      },
      "source": [
        "def get_data(url, filename):\n",
        "    \"\"\"\n",
        "    Download Data if the filename doesnot exist already \n",
        "    Uses Tqdm to show download progress \n",
        "\n",
        "    \"\"\"\n",
        "    import os \n",
        "    from urllib.request import urlretrieve\n",
        "\n",
        "    if not os.path.exists(filename):\n",
        "        dirname = os.path.dirname(filename)\n",
        "        if not os.path.exists(dirname):\n",
        "            os.makedirs(dirname)\n",
        "\n",
        "        with TqdmUpto(unit = 'B', unit_scale=True, miniters=1, desc=url.split('/')[-1]) as t:\n",
        "            urlretrieve(url, filename, reporthook=t.Update_to)\n",
        "        \n",
        "    else : \n",
        "        print(\"Already Exist\")\n",
        "    \n",
        "embedding_url = 'http://nlp.stanford.edu/data/glove.6B.zip'\n",
        "get_data(embedding_url, 'data/glove.6B.zip')\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "glove.6B.zip: 862MB [02:42, 5.30MB/s]                           \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3nnspPTP-tt",
        "outputId": "a01d2df2-7e26-4568-c060-06cea0f57e3b"
      },
      "source": [
        " !unzip data/glove.6B.zip \n",
        " !mv -v glove.6B.300d.txt data/glove.6B.300d.txt \n",
        " !mv -v glove.6B.200d.txt data/glove.6B.200d.txt \n",
        " !mv -v glove.6B.100d.txt data/glove.6B.100d.txt \n",
        " !mv -v glove.6B.50d.txt data/glove.6B.50d.txt"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  data/glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n",
            "renamed 'glove.6B.300d.txt' -> 'data/glove.6B.300d.txt'\n",
            "renamed 'glove.6B.200d.txt' -> 'data/glove.6B.200d.txt'\n",
            "renamed 'glove.6B.100d.txt' -> 'data/glove.6B.100d.txt'\n",
            "renamed 'glove.6B.50d.txt' -> 'data/glove.6B.50d.txt'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--Q15D7g-QxP"
      },
      "source": [
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "\n",
        "glove_input_file = 'data/glove.6B.300d.txt'\n",
        "word2vec_output_file = 'data/glove.6B.300d.txt.word2vec'\n",
        "\n",
        "import os \n",
        "if not  os.path.exists(word2vec_output_file):\n",
        "    glove2word2vec(glove_input_file, word2vec_output_file)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJcH80pOPwAy",
        "outputId": "db6d567c-326c-42c1-cb4f-ce768c76adf8"
      },
      "source": [
        "%%time \n",
        "\n",
        "from gensim.models import KeyedVectors\n",
        "filename = word2vec_output_file\n",
        "embed = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 58s, sys: 3.55 s, total: 2min 2s\n",
            "Wall time: 2min\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CUUcJX7QpDF"
      },
      "source": [
        "assert embed['awesome'] is not None\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wE_li-PRK1s",
        "outputId": "ddca9fbe-d301-4002-80d8-d2a685c94c8a"
      },
      "source": [
        "embed['for']"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-2.4132e-01,  1.2063e-01,  1.9190e-01, -2.6692e-01,  6.1076e-02,\n",
              "       -2.2878e-02,  5.8017e-01, -2.2533e-01, -2.0644e-01, -1.6361e+00,\n",
              "        2.7715e-01,  1.5026e-01, -3.1691e-01,  3.8411e-01,  3.2003e-02,\n",
              "       -1.2901e-01, -5.3065e-02, -5.5874e-03,  1.0467e-01, -4.2931e-01,\n",
              "       -2.3605e-01,  2.6159e-01,  7.0261e-02,  4.6544e-02, -2.0760e-01,\n",
              "       -2.3013e-01,  1.8501e-02,  2.5844e-01,  1.2839e-01,  1.6461e-01,\n",
              "       -2.3486e-02,  2.0511e-01,  1.8169e-01,  3.0549e-01, -1.1893e+00,\n",
              "       -4.0416e-01, -1.9842e-01,  1.4848e-01,  1.3756e-01, -9.3425e-02,\n",
              "        1.9290e-01, -4.9650e-02,  3.8317e-02, -2.9397e-01, -7.9036e-02,\n",
              "       -1.0161e-01,  1.1877e-01,  4.8220e-01, -2.9784e-01,  2.1025e-01,\n",
              "        1.2835e-01, -2.6482e-01,  3.6112e-01, -3.0893e-01, -4.4381e-01,\n",
              "        1.8737e-01, -2.1541e-01,  3.9490e-01, -2.2203e-02, -3.5489e-01,\n",
              "       -3.6777e-01,  1.4181e-01,  4.1243e-01, -7.1339e-01, -7.3703e-02,\n",
              "       -3.3782e-01,  2.0737e-01, -2.8501e-01,  4.7233e-01, -1.5250e-01,\n",
              "        6.5531e-02,  5.3530e-01,  2.5701e-01, -2.5569e-01, -9.6976e-02,\n",
              "       -1.1460e-01,  1.8648e-01,  6.3131e-01, -1.0587e-01, -1.7148e-01,\n",
              "       -2.2473e-01, -6.1003e-02,  4.7845e-04,  2.2570e-01,  4.5379e-02,\n",
              "        8.5725e-02, -6.0717e-02,  4.3170e-02, -1.1603e-01,  2.5903e-01,\n",
              "       -3.0215e-01,  2.8587e-01, -2.8818e-01, -2.1763e-01, -2.3948e-01,\n",
              "        4.3288e-01, -4.0840e-02, -3.6206e-01,  2.2116e-02,  1.3942e-01,\n",
              "       -7.0819e-02, -6.2650e-02, -1.6719e-01,  2.5075e-01, -7.3938e-02,\n",
              "       -1.8153e-01, -8.9108e-02,  1.2788e-01, -5.0767e-01, -3.0892e-01,\n",
              "        1.8676e-01,  2.2779e-01, -1.1462e-01, -2.1483e-01, -1.5121e-01,\n",
              "       -2.9170e-01, -1.0897e-01,  2.2638e-01, -7.4798e-02, -1.5148e-01,\n",
              "       -1.3637e-01,  9.2040e-02,  2.7222e-01,  1.9741e-01, -6.2062e-02,\n",
              "       -2.7252e-01, -1.5272e-01, -1.0209e-01,  5.3098e-02,  2.2801e-02,\n",
              "        1.0910e-01,  2.1148e-01, -2.0907e-02,  1.0857e-01, -4.9408e-02,\n",
              "        1.1124e-01, -1.7701e-01, -1.2100e-03, -1.4335e-01, -9.6521e-02,\n",
              "        7.9911e-02,  1.9257e-01,  3.4096e-01,  1.4215e-01, -3.6738e-01,\n",
              "       -3.2070e-01, -1.9761e-01,  1.5248e-01, -2.6763e-01, -1.8512e-01,\n",
              "        4.3069e-01,  1.6150e-01,  2.5156e-02, -1.8902e-01,  2.5434e-01,\n",
              "       -4.9355e-01, -5.1217e-01, -1.3753e-01,  2.2434e-01, -1.7512e-01,\n",
              "       -7.3847e-02, -2.6023e-01,  2.6365e-01,  1.3591e-01, -1.7958e-01,\n",
              "        5.6764e-01, -1.7501e-01, -9.4047e-02,  9.9351e-02,  1.8683e-01,\n",
              "        2.2519e-01, -2.9088e-01, -7.9464e-01,  2.1899e-01,  7.1638e-02,\n",
              "        1.8663e-01, -2.7274e-01,  1.0228e-01, -7.8778e-01,  6.7060e-01,\n",
              "       -4.3824e-02, -9.9652e-02,  6.6548e-01, -1.2354e-01, -4.9125e-01,\n",
              "        3.9520e-02, -1.6488e-01, -2.0250e-02, -3.2289e-01,  8.3526e-02,\n",
              "       -1.4496e-01,  3.2379e-01, -2.3525e-01, -2.4786e-01, -2.8118e-02,\n",
              "       -9.0129e-02,  2.2810e-01,  1.0043e-01,  1.4150e-01, -3.4989e-02,\n",
              "        8.9417e-01,  1.3070e-01,  5.9509e-02,  1.4980e-01,  2.0001e-01,\n",
              "        1.6255e-01,  2.9000e-02,  1.7797e-01,  5.9021e-02, -9.5148e-02,\n",
              "        2.0483e-01, -9.2795e-02, -4.9022e-02,  3.8437e-01,  1.6782e-01,\n",
              "        3.9579e-01, -6.2480e-01,  3.1983e-01, -1.0613e-01,  5.3248e-02,\n",
              "        2.8483e-01, -2.6865e-01, -6.3264e-01,  3.2117e-01, -1.5954e-01,\n",
              "       -2.3866e-01,  5.6190e-02, -8.4656e-02,  1.4805e-02, -1.5208e-01,\n",
              "        1.9622e-01,  8.3831e-02,  1.8074e-01,  1.9600e-01,  5.7978e-01,\n",
              "       -7.2943e-02,  4.3570e-01,  5.2403e-01,  1.0477e-01,  5.4837e-01,\n",
              "       -6.6689e-01,  5.1188e-01,  2.2309e-01, -1.7447e-02, -7.1843e-01,\n",
              "        7.8075e-02,  4.9534e-01,  5.5915e-02,  1.3700e-01, -6.2998e-02,\n",
              "       -1.6348e-01,  5.2879e-01, -1.5893e-01, -1.9031e-01,  2.8423e-01,\n",
              "       -2.3602e-01, -1.8803e-01, -3.4223e-01,  9.5075e-02,  5.0825e-02,\n",
              "       -3.3548e-01, -6.4552e-01,  1.6552e-01,  1.9078e-01, -2.0446e-02,\n",
              "        5.6518e-01, -1.5641e-01,  3.8419e-01,  1.0524e-01,  2.4834e-01,\n",
              "        1.6900e-01, -2.2751e-01,  2.7999e-01,  2.7417e-02,  1.4738e-01,\n",
              "        3.2636e-01, -2.7652e+00,  2.8688e-01,  4.2632e-01,  2.5070e-02,\n",
              "       -6.6260e-01, -3.5313e-01, -1.6386e-01,  5.4448e-01, -5.4815e-02,\n",
              "        5.4757e-01,  6.5762e-03,  2.7822e-01,  1.8534e-01,  6.2874e-02,\n",
              "       -3.1926e-01, -1.7975e-01,  2.2093e-01,  2.2999e-01,  1.8652e-01,\n",
              "        2.1208e-01, -1.4143e-01, -6.3158e-02, -3.2837e-01,  1.5507e-01],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Za0eNP1NRPMw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WRPT8H1RYHj"
      },
      "source": [
        "# BOT : FOOD ORDER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xRAndLiRcHg"
      },
      "source": [
        "cuisine_refs = [\"mexican\", \"thai\", \"british\", \"american\", \"italian\"]\n",
        "sample_sentence = \"I am looking for a cheap Indian or Chinese place in Indiranagar\" "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjYdaJNgRzlr",
        "outputId": "c0d4fd0f-5d58-456a-d536-d53737635699"
      },
      "source": [
        "tokens = sample_sentence.split()\n",
        "tokens = [x.lower().strip() for x in tokens]\n",
        "\n",
        "threshold = 18.3\n",
        "found = []\n",
        "for term in tokens:\n",
        "    if term in embed.vocab: \n",
        "        scores = []\n",
        "        for C in cuisine_refs: \n",
        "            scores.append(np.dot(embed[C], embed[term].T)) \n",
        "\n",
        "        mean_score = np.mean(scores)\n",
        "        print(f\"{term} : {mean_score}\")\n",
        "\n",
        "        if mean_score > threshold: \n",
        "            found.append(term)\n",
        "print(found) "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i : 8.132120132446289\n",
            "am : 6.354741096496582\n",
            "looking : 7.448504447937012\n",
            "for : 10.627421379089355\n",
            "a : 11.809560775756836\n",
            "cheap : 7.09670877456665\n",
            "indian : 18.64516258239746\n",
            "or : 9.692893981933594\n",
            "chinese : 19.09498405456543\n",
            "place : 7.651237487792969\n",
            "in : 10.085711479187012\n",
            "['indian', 'chinese']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kI3ZQ4NBTa8t",
        "outputId": "71c31eea-6d42-446e-b522-c087b53809e8"
      },
      "source": [
        "# LET\"S CLASSIFY INTENT \n",
        "def sum_vecs(embed, text):\n",
        "    tokens = text.split(' ')\n",
        "    vec = np.zeros(embed.vector_size)\n",
        "\n",
        "    for idx, term in enumerate(tokens):\n",
        "        if term in embed.vocab : \n",
        "            vec = vec + embed[term]\n",
        "    return vec\n",
        "\n",
        "\n",
        "sentence_vector = sum_vecs(embed, sample_sentence)\n",
        "print(sentence_vector.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(300,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwI-O7hWV_JX"
      },
      "source": [
        "data={\n",
        "  \"greet\": {\n",
        "    \"examples\" : [\"hello\",\"hey there\",\"howdy\",\"hello\",\"hi\",\"hey\",\"hey ho\"],\n",
        "    \"centroid\" : None\n",
        "  },\n",
        "  \"inform\": {\n",
        "    \"examples\" : [\n",
        "        \"i'd like something asian\",\n",
        "        \"maybe korean\",\n",
        "        \"what mexican options do i have\",\n",
        "        \"what italian options do i have\",\n",
        "        \"i want korean food\",\n",
        "        \"i want german food\",\n",
        "        \"i want vegetarian food\",\n",
        "        \"i would like chinese food\",\n",
        "        \"i would like indian food\",\n",
        "        \"what japanese options do i have\",\n",
        "        \"korean please\",\n",
        "        \"what about indian\",\n",
        "        \"i want some chicken\",\n",
        "        \"maybe thai\",\n",
        "        \"i'd like something vegetarian\",\n",
        "        \"show me french restaurants\",\n",
        "        \"show me a cool malaysian spot\",\n",
        "        \"where can I get some spicy food\"\n",
        "    ],\n",
        "    \"centroid\" : None\n",
        "  },\n",
        "  \"deny\": {\n",
        "    \"examples\" : [\n",
        "      \"nah\",\n",
        "      \"any other places ?\",\n",
        "      \"anything else\",\n",
        "      \"no thanks\"\n",
        "      \"not that one\",\n",
        "      \"i do not like that place\",\n",
        "      \"something else please\",\n",
        "      \"no please show other options\"\n",
        "    ],\n",
        "    \"centroid\" : None\n",
        "  },\n",
        "    \"affirm\":{\n",
        "        \"examples\":[\n",
        "            \"yeah\",\n",
        "            \"that works\",\n",
        "            \"good, thanks\",\n",
        "            \"this works\",\n",
        "            \"sounds good\",\n",
        "            \"thanks, this is perfect\",\n",
        "            \"just what I wanted\"\n",
        "        ],\n",
        "        \"centroid\": None\n",
        "    }\n",
        "\n",
        "}"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4jq7lKEWPW_"
      },
      "source": [
        "def get_centroid(embed, examples):\n",
        "    C = np.zeros((len(examples), embed.vector_size))\n",
        "\n",
        "    for idx, text in enumerate(examples):\n",
        "        C[idx,:] = sum_vecs(embed, text)\n",
        "\n",
        "    \n",
        "    centroid = np.mean(C, axis=0)\n",
        "    assert centroid.shape[0] == embed.vector_size\n",
        "    return centroid "
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XW7hxv-XTSn"
      },
      "source": [
        "for label in data.keys():\n",
        "    data[label][\"centroid\"] = get_centroid(embed, data[label][\"examples\"])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jujfQskjXljr"
      },
      "source": [
        ""
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNDdlQf4XmuQ",
        "outputId": "d23888d4-324f-4cb1-867a-49df543f48f9"
      },
      "source": [
        "for label in data.keys():\n",
        "    print(f\"{label}: {data[label]['examples']}\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "greet: ['hello', 'hey there', 'howdy', 'hello', 'hi', 'hey', 'hey ho']\n",
            "inform: [\"i'd like something asian\", 'maybe korean', 'what mexican options do i have', 'what italian options do i have', 'i want korean food', 'i want german food', 'i want vegetarian food', 'i would like chinese food', 'i would like indian food', 'what japanese options do i have', 'korean please', 'what about indian', 'i want some chicken', 'maybe thai', \"i'd like something vegetarian\", 'show me french restaurants', 'show me a cool malaysian spot', 'where can I get some spicy food']\n",
            "deny: ['nah', 'any other places ?', 'anything else', 'no thanksnot that one', 'i do not like that place', 'something else please', 'no please show other options']\n",
            "affirm: ['yeah', 'that works', 'good, thanks', 'this works', 'sounds good', 'thanks, this is perfect', 'just what I wanted']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZPwkZoNXvEs"
      },
      "source": [
        "def get_intent(embed, data, text):\n",
        "    intents = list(data.keys())\n",
        "    vec = sum_vecs(embed, text)\n",
        "    scores = np.array([ np.linalg.norm(vec-data[label][\"centroid\"]) for label in intents ])\n",
        "    return intents[np.argmin(scores)]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyMvN-XFYw-k",
        "outputId": "fa8d249e-e435-4e0f-969f-3d061d3f93a6"
      },
      "source": [
        "for text in [\"hey \",\"i am looking for chinese food\",\"not for me\", \"ok, this is good\"]:\n",
        "    print(f\"text : '{text}', predicted_label : '{get_intent(embed, data, text)}'\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "text : 'hey ', predicted_label : 'greet'\n",
            "text : 'i am looking for chinese food', predicted_label : 'inform'\n",
            "text : 'not for me', predicted_label : 'deny'\n",
            "text : 'ok, this is good', predicted_label : 'affirm'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2J9Eq3cZPH-",
        "outputId": "a61071ee-d421-43d8-e15c-4d76f2d6140f"
      },
      "source": [
        "for text in [\"Machine Learning University - Accelerated Natural Language Processing - Lectures go from introduction to NLP and text processing to Recurrent Neural Networks and Transformers. Material can be found here.\"]:\n",
        "    print(f\"text : '{text}', predicted_label : '{get_intent(embed, data, text)}'\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "text : 'Machine Learning University - Accelerated Natural Language Processing - Lectures go from introduction to NLP and text processing to Recurrent Neural Networks and Transformers. Material can be found here.', predicted_label : 'inform'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRuIUHcAZdVd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzxMutc9ZjQK"
      },
      "source": [
        "# RESPONSES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yi24ejCGc9hs"
      },
      "source": [
        "templates = {\n",
        "        \"utter_greet\": [\"hey there!\", \"Hey! How you doin'? \"],\n",
        "        \"utter_options\": [\"ok, let me check some more\"],\n",
        "        \"utter_goodbye\": [\"Great, I'll go now. Bye bye\", \"bye bye\", \"Goodbye!\"],\n",
        "        \"utter_default\": [\"Sorry, I didn't quite follow\"],\n",
        "        \"utter_confirm\": [\"Got it\", \"Gotcha\", \"Your order is confirmed now\"]\n",
        "    }"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "po6cZEz3c_iR"
      },
      "source": [
        "response_map = {\n",
        "    \"greet\": \"utter_greet\",\n",
        "    \"affirm\": \"utter_goodbye\",\n",
        "    \"deny\": \"utter_options\",\n",
        "    \"inform\": \"utter_confirm\",\n",
        "    \"default\": \"utter_default\",\n",
        "}"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xH0osmj7dCBT"
      },
      "source": [
        "import random \n",
        "def get_bot_response(bot_response_map, bot_templates, intent):\n",
        "    if intent not in list(response_map):\n",
        "        intent = \"default\"\n",
        "    select_template = bot_response_map[intent]\n",
        "    templates = bot_templates[select_template]\n",
        "    return random.choice(templates)    "
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rz5ofCDSdbig",
        "outputId": "7dfc1265-265d-4b91-e481-a0cb5c66f58e"
      },
      "source": [
        "user_intent = get_intent(embed, data, \"show me menu\")\n",
        "get_bot_response(response_map, templates, user_intent)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Great, I'll go now. Bye bye\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fIKVxKbdjkA",
        "outputId": "d52620d3-13c0-43e4-9f35-a94d65ed1ff3"
      },
      "source": [
        "for i in range(5):\n",
        "    text = str(input())\n",
        "    user_intent = get_intent(embed, data, text)\n",
        "    bot_reply = get_bot_response(response_map, templates, user_intent)\n",
        "    print(f\"text : '{text}', intent: {user_intent}, bot: {bot_reply}\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hey\n",
            "text : 'hey', intent: greet, bot: Hey! How you doin'? \n",
            "i am looking for south indian food\n",
            "text : 'i am looking for south indian food', intent: inform, bot: Got it\n",
            "not for me\n",
            "text : 'not for me', intent: deny, bot: ok, let me check some more\n",
            "ok, this is good\n",
            "text : 'ok, this is good', intent: affirm, bot: bye bye\n",
            "bye\n",
            "text : 'bye', intent: greet, bot: hey there!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vQhR3oyd5b3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}